<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>DeBERTa: Decoding-enhanced BERT with Disentangled Attention(2020)</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="37b23cf8-ed3d-4318-aafe-a7a7b10c8855" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">🔎</span></div><h1 class="page-title"><strong>DeBERTa: Decoding-enhanced BERT with Disentangled Attention(2020)</strong></h1><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-checkbox"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesCheckbox"><path d="M3.85742 14.4561H12.1357C13.6123 14.4561 14.3779 13.6904 14.3779 12.2344V3.91504C14.3779 2.45215 13.6123 1.69336 12.1357 1.69336H3.85742C2.38086 1.69336 1.61523 2.45215 1.61523 3.91504V12.2344C1.61523 13.6973 2.38086 14.4561 3.85742 14.4561ZM3.93945 13.1162C3.30371 13.1162 2.95508 12.7812 2.95508 12.1182V4.02441C2.95508 3.36133 3.30371 3.0332 3.93945 3.0332H12.0537C12.6826 3.0332 13.0381 3.36133 13.0381 4.02441V12.1182C13.0381 12.7812 12.6826 13.1162 12.0537 13.1162H3.93945ZM7.26855 11.3115C7.51465 11.3115 7.72656 11.1885 7.87012 10.9697L10.9258 6.19141C11.0146 6.04785 11.0967 5.88379 11.0967 5.72656C11.0967 5.3916 10.7959 5.16602 10.4746 5.16602C10.2695 5.16602 10.085 5.27539 9.94141 5.50781L7.24121 9.8418L5.96973 8.22168C5.80566 8.00977 5.6416 7.93457 5.43652 7.93457C5.10156 7.93457 4.8418 8.20117 4.8418 8.54297C4.8418 8.70703 4.90332 8.85742 5.01953 9.00098L6.63281 10.9697C6.81738 11.209 7.01562 11.3115 7.26855 11.3115Z"></path></svg></span>복습</th><td><div class="checkbox checkbox-off"></div></td></tr></tbody></table></header><div class="page-body"><p id="e195b5ea-f60f-4826-8a0a-055b66c82ee3" class="">
</p><figure id="baf966a6-e434-45ed-9df9-5d4b9e58e701"><div class="source"><a href="DeBERTa%20Decoding-enhanced%20BERT%20with%20Disentangled%20A%2037b23cf8ed3d4318aafea7a7b10c8855/deberta_decoding_enhanced_bert.pdf">deberta_decoding_enhanced_bert.pdf</a></div></figure><figure id="9c5914d5-028a-48fe-a95e-19fdfd2d4ca7"><a href="https://github.com/microsoft/DeBERTa" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">GitHub - microsoft/DeBERTa: The implementation of DeBERTa</div><div class="bookmark-description">The implementation of DeBERTa. Contribute to microsoft/DeBERTa development by creating an account on GitHub.</div></div><div class="bookmark-href"><img src="https://github.com/fluidicon.png" class="icon bookmark-icon"/>https://github.com/microsoft/DeBERTa</div></div><img src="https://opengraph.githubassets.com/30876bd0282ada1be122e97390a5d0d504a1e94bcab3dd15936a77d6ce3b7a71/microsoft/DeBERTa" class="bookmark-image"/></a></figure><p id="82a871f6-0fb0-44fe-b521-47b404ff47be" class="">Transformer-based PLM(Pre-trained Language Model)</p><p id="77190b7e-fa3d-494b-aba0-fa4e35bddb4d" class="">→ 자연어 처리 모델은 Encoder-Decoder가 결합한 형태로 변해가는 추세이며, 그 중에서도 transformer 기반의 모델이 강력한 성능을 보임</p><p id="cac7f1b5-5186-405e-8f8f-df366b24bca1" class="">→ Transformer의 Encoder를 사용한 BERT의 Masked Language Model을 기반으로 다양한 응용 모델이 연구됨에 따라 input noise에 강건하고 양방향의 context 정보를 보다 깊게 고려 가능</p><figure id="b6556725-abe6-48d1-acaf-5ce07b4d7ed9" class="image"><a href="DeBERTa%20Decoding-enhanced%20BERT%20with%20Disentangled%20A%2037b23cf8ed3d4318aafea7a7b10c8855/Untitled.png"><img style="width:1328px" src="DeBERTa%20Decoding-enhanced%20BERT%20with%20Disentangled%20A%2037b23cf8ed3d4318aafea7a7b10c8855/Untitled.png"/></a></figure><figure id="d129f140-9346-41fb-b4cf-f6bcd4afa734"><a href="https://velog.io/@tm011899/BERT-언어모델" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">BERT 언어모델</div><div class="bookmark-description">BERT(Bidirectional Encoder Representations from Transformers)는 구글에서 2018년에 발표한 언어 모델로, Transformer 아키텍처를 기반으로 하고 양방향(bidirectional) 학습을 사용하여 이전의 모델보다</div></div><div class="bookmark-href"><img src="https://static.velog.io/favicons/apple-icon-152x152.png" class="icon bookmark-icon"/>https://velog.io/@tm011899/BERT-언어모델</div></div><img src="https://velog.velcdn.com/images/tm011899/post/b70bc6f6-2b06-4ae7-b73d-96cbb4f11950/image.jpg" class="bookmark-image"/></a></figure><p id="baf935fc-810c-4e46-868e-d9cbd7f187d9" class=""><code>Disentangled Representation</code></p><p id="c475fe5e-cee1-4b7b-89e7-6a96a7c984f3" class="">→ 서로 뒤얽혀 있는 특징 요소들을 독립적으로 풀어서 표현하기!<br/>데이터의 다양성을 설명하는 latent 요소들을 분리하여 표현함으로써 interpretability를 높임<br/></p><p id="c106c197-e817-46ed-b36b-ef9bfdb32ccb" class=""><code>Positional Embedding</code></p><p id="719af38c-44ca-49d4-a706-a84dce51a69d" class="">→ 단어의 위치 정보를 특정 차원의 벡터로 표현한 것 </p><p id="19733e60-5dfa-47ac-a788-2e134d92cf2d" class="">1) Absolute Positional Embedding <br/>어떤 입력 문장이더라도 각 단어의 위치의 Positional Embedding 값은 동일한 값이 사용됨<br/>각 토큰의 절대적 위치 정보, 절대적으로 떨어진 거리 정보를 파악할 수 있다 → distance<br/></p><p id="ef728d22-129f-4132-86c7-3a2ac6606f09" class="">2)  Relative Positional Embedding<br/>특정 위치의 단어를 기준으로 일정 길이 이내에 위치한 언어와의 상대적 거리 관계 정보를 반영함<br/>각 단어 간의 위치 차이가 index로 사용되며 짝지어진 토큰 간의 상대적 위치 정보를 파악할 수 있다, → directionn and distance<br/></p><hr id="e5089a82-d606-4f11-a3f0-6e6ce0148ccc"/><figure id="617e3ccd-3542-4541-a076-e5d511f01771" class="image"><a href="DeBERTa%20Decoding-enhanced%20BERT%20with%20Disentangled%20A%2037b23cf8ed3d4318aafea7a7b10c8855/Untitled%201.png"><img style="width:1299px" src="DeBERTa%20Decoding-enhanced%20BERT%20with%20Disentangled%20A%2037b23cf8ed3d4318aafea7a7b10c8855/Untitled%201.png"/></a></figure><figure id="fd407028-4f17-4717-8e2a-e1a8e0392dea"><div class="source"><a href="https://www.youtube.com/watch?v=hNTkpNk7v-I">https://www.youtube.com/watch?v=hNTkpNk7v-I</a></div></figure><p id="69b3b15e-bd87-425b-9bce-ed412cabe731" class="">
</p><h3 id="c460a881-24f7-4093-a1f4-a6ab9548e9bf" class=""><strong>1. </strong>논문 내 주요 방법론</h3><ul id="afa4295b-0b58-4d9f-8bc5-9aca1f0e84a5" class="bulleted-list"><li style="list-style-type:disc">Disentangled Attention Mechanism: 각 단어를 독립적인 두 벡터로 표현, 하나는 &#x27;내용(content)&#x27;을 다른 하나는 &#x27;위치(position)&#x27;을 나타낸다. 단어 간의 attention 가중치는 그들의 내용과 상대적 위치에 대해 분리된 행렬을 사용하여 계산된다.</li></ul><ul id="df21a6d7-b769-4e4a-b941-717beb8fa5c7" class="bulleted-list"><li style="list-style-type:disc">Enhanced Mask Decoder: 모델의 학습(pre-training) 단계에서 각 토큰의 절대적 위치(absolute position)를 디코딩 레이어에 포함시킨다. <br/>→  문장에서 단어가 쓰인 순서와 위치에 따른 미묘한 의미 차이를 더 잘 이해<br/></li></ul><h3 id="b8211f03-53b9-457e-adc1-2277c36af1bb" class="">2. 논문에서 풀고자 하는 문제</h3><ul id="5d4cbccc-c875-407d-8d7d-61a165517048" class="bulleted-list"><li style="list-style-type:disc">BERT와 같은 모델들이 단어 간의 복잡한 관계를 포착하는 데 있어서 갖는 한계점<br/>→ 단어의 정확한 위치 정보와 이들 간의 상호작용을 효과적으로 모델링하지 못했기 때문<br/></li></ul><ul id="2157614f-67d8-4cfe-ac61-cc71d3b2152c" class="bulleted-list"><li style="list-style-type:disc">기존 모델들의 단어의 내용과 위치 정보를 통합적으로 처리하는 방식<br/>→ 모델이 단어 간의 관계를 더욱 정교하게 학습하는 데 한계 발생<br/></li></ul><h3 id="4b3a14c5-28d2-4686-b347-6d3523e051cf" class="">3. 기존의 연구들이 이 문제를 풀어온 방식</h3><p id="57e72bc0-d64c-45b3-82bd-909a743945d3" class="">문장 내 의미, 단어 간의 관계를 파악하기 위해 주로 어텐션 메커니즘을 사용했고, 위치 정보는 상대적인 위치 표현 또는 고정된 위치 인코딩을 통해 간접적으로만 반영했다.</p><h3 id="19ef71af-00e7-449f-92c5-ef9856e40082" class="">4. 기존의 연구 대비 이 논문의 강점</h3><ul id="10da4c6e-5b51-4729-a128-7cb0fbc054d2" class="bulleted-list"><li style="list-style-type:disc"><code>Disentangled Attention</code><br/>대부분의 트랜스포머 기반 모델은 단어와 위치 정보를 하나의 벡터로 결합하여 어텐션 계산에 사용한다. 그러나 DeBERTa는 단어의 내용(content)과 위치(position) 정보를 분리하여 처리하는 Disentangled Attention 메커니즘을 도입하여, 모델은 단어 간의 내용적인 관련성(content-wise attention)과 각 단어의 상대적인 위치에 따른 관계(position-wise attention)를 더욱 세밀하게 파악할 수 있게 되었다.<br/><ul id="e46d8078-4851-4b89-861c-9e27ab343a6e" class="bulleted-list"><li style="list-style-type:circle">Transformer-xl 처럼  addictive하게 attention을 분해</li></ul><ul id="a39fb635-7ae2-4c8a-815b-21fbdbfdf93f" class="bulleted-list"><li style="list-style-type:circle">Shaw, Transformer-xl과 다르게 position-to-content term을 살림<br/>→ query token의 위치가 달라지는 부분도 반영<br/></li></ul><ul id="7962f64c-1746-4dea-902f-b153e7e98da2" class="bulleted-list"><li style="list-style-type:circle">Position-to-position term은 PRE에서 불필요하기 때문에 제거</li></ul></li></ul><ul id="3f1770b4-59a0-486d-87ac-d6ea751f6ea2" class="bulleted-list"><li style="list-style-type:disc"><code>Enhanced Mask Decoder</code><br/>Pre-training 단계에서 Masked Language Model(MLM) 작업을 수행할 때 decoding layer에 절대 위치를 포함하는 Enhanced Mask Decoder를 사용한다. 이는 모델이 [Mask] 토큰을 예측할 때 문장 내 각 단어의 절대적 위치 정보를 효과적으로 활용하여 정확도를 높이는 데 기여했다.<br/><ul id="724c27d1-bf60-46c5-9d13-29f75876e2df" class="bulleted-list"><li style="list-style-type:circle">Absolute position information의 중요성</li></ul></li></ul><ul id="8f681e7b-5d03-424a-8b78-a42d47ff42c3" class="bulleted-list"><li style="list-style-type:disc">Scale Invariant Fine-Tuning: DeBERTa 모델을 생성하고 SiFT 계층을 모델에 연결<br/>→ 모델의 일반화 능력을 개선하고, 다양한 크기 및 범위의 데이터셋에 대해 모델의 성능을 극대화<br/><ul id="8045c5a6-6812-4f84-9331-939d5281dd7e" class="bulleted-list"><li style="list-style-type:circle">Adversarial Training은 모델의 일반화에 도움을 준다.</li></ul><ul id="c793096b-b9be-4c92-bad5-1781286b9c0a" class="bulleted-list"><li style="list-style-type:circle">Word embedding을 normalize해주고 Perturbation을 추가하자.</li></ul></li></ul><h3 id="e07c06ac-52f2-4f7a-bc35-2d348cd4bc77" class="">5. 이 논문을 토대로 한 Future Work에는 무엇이 있을 수 있는지</h3><ul id="7383d256-aab7-4e82-a865-7dc9fb5f184d" class="bulleted-list"><li style="list-style-type:disc">DeBERTa의 disentangled attention 메커니즘의 강점을 활용하여 복잡한 언어적 문맥에서 더 섬세한 이해를 가능하게 하는 연구 진행<br/>→ 다중 언어(multilingual) 데이터셋이나 상호 문화적 텍스트(cross-cultural texts)에 대한 모델링<br/></li></ul><ul id="4c9d4b69-841d-4fdc-886c-2ac82e2ce945" class="bulleted-list"><li style="list-style-type:disc">실시간 언어 처리(real-time language processing) 향상<br/>→ 모델의 반응 시간을 개선하여 실시간 대화나 번역 시스템에서의 활용, 속도와 정확성의 균형을 맞추는 데 중점을 둔다.<br/></li></ul><ul id="baf0e942-ffc6-424d-8a41-ead668a3c24a" class="bulleted-list"><li style="list-style-type:disc">저자원 언어(low-resource languages)에 대한 적용<br/>→ 대량의 데이터가 없는 언어에 대해 DeBERTa를 적용하여 효과적인 언어 모델을 구축<br/></li></ul><ul id="683016de-8fd6-42cd-9e03-8c4c249be0e8" class="bulleted-list"><li style="list-style-type:disc">인과 관계 학습(cause-and-effect learning)<br/>DeBERTa 모델을 활용하여 텍스트 내의 원인과 결과 관계를 파악하고 이해하는 능력을 향상<br/></li></ul><ul id="075e78d9-6e66-4a33-bf79-33d14e4f6ab2" class="bulleted-list"><li style="list-style-type:disc">감정 분석과 개인화(personalization in sentiment analysis)<br/>→ 개인별 언어 사용 패턴을 분석하여 각 개인의 감정을 더 잘 파악하고 예측할 수 있도록 하는 연구<br/></li></ul><ul id="7939856d-7297-4774-b45d-69a351c4c39f" class="bulleted-list"><li style="list-style-type:disc">윤리적 NLP 연구(ethical aspects of NLP)<br/>→ DeBERTa를 활용하여 편향이나 왜곡 없이 텍스트를 처리하는 방법론을 개발<br/></li></ul></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>